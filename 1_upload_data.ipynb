{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook helps to upload data from local to hugging face!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset, Audio\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Audio Data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_data(audio_dir):\n",
    "    audio_files = []\n",
    "    file_names = []\n",
    "    \n",
    "    # Iterate through audio directory\n",
    "    for filename in os.listdir(audio_dir):\n",
    "        if filename.endswith('.wav'):# Adjust this based on your audio file format\n",
    "            # Load audio file\n",
    "            audio_path = os.path.join(audio_dir, filename)\n",
    "            audio_files.append(audio_path)\n",
    "\n",
    "            file_names.append(filename)\n",
    "    return {\n",
    "        'audio_path': audio_files,\n",
    "        'file_names': file_names,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload Chinese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload chinese_b1 and chinese_b2 together. DONT do below chinese_b1 and chinese_b2 if doing this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a0d92e99404676a3dd1a268d9dd107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e07353ba86494993d10d51d155ca45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf119b5df0e4ccc9fb119f350050b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ce0d82d62c40e39af752a422009dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9d3b38a05540c389d8f273954fbd55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/141 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45dc955cc0e4000b8cd171cb2dcfaf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d710c0b3634f97a692dcb88bb1cecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/581 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/avintech/chinese_children_speech/commit/6c1443f3c3de397085441def482342f785c9b907', commit_message='Upload dataset', commit_description='', oid='6c1443f3c3de397085441def482342f785c9b907', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_audio_dir = \"data/recordings/chinese/chinese_b1\"\n",
    "b1_audio_data = load_audio_data(b1_audio_dir)\n",
    "b1_audio_df = pd.DataFrame(b1_audio_data)\n",
    "\n",
    "b1_df = pd.read_csv(\"data/csv/chinese_b1.csv\")\n",
    "b1_df['file_names'] = b1_df['file_names'].apply(lambda x: x + '.wav')\n",
    "b1_df = pd.merge(b1_df, b1_audio_df, on='file_names', how='inner')\n",
    "\n",
    "b2_audio_dir = \"data/recordings/chinese/chinese_b2\"\n",
    "b2_audio_data = load_audio_data(b2_audio_dir)\n",
    "b2_audio_df = pd.DataFrame(b2_audio_data)\n",
    "\n",
    "b2_df = pd.read_csv(\"data/csv/chinese_b2.csv\")\n",
    "b2_df = pd.merge(b2_df, b2_audio_df, on='file_names', how='inner')\n",
    "\n",
    "#merge b1 and b2\n",
    "df = pd.concat([b1_df, b2_df], ignore_index=True)\n",
    "df = df.drop(columns=['remarks'])\n",
    "df = df.dropna(subset=['fluency','spoken_text'])\n",
    "\n",
    "dict_data = df.to_dict(orient='list')\n",
    "audio_dataset = Dataset.from_dict(dict_data).cast_column(\"audio_path\", Audio())\n",
    "\n",
    "audio_dataset.train_test_split(test_size=0.2).push_to_hub('chinese_children_speech')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chinese_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3828ee38ce44c9995bddac18ed3e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571feb19becc411f828c461179b1b9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/456 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65bd516d7e3e4c40823a120e25d89f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad57c26fa7e24387b7d94598858dd8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11029fbdb7b14b2f89e004b59805d32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/114 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7452a2133d4498d847b74a34566218b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1a1495115f4f11a41a0b167608e259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/549 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/avintech/chinese_b1/commit/271ec7872ca9c793de5b385f3c27a5f0a5b8a2c4', commit_message='Upload dataset', commit_description='', oid='271ec7872ca9c793de5b385f3c27a5f0a5b8a2c4', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_audio_dir = \"data/recordings/chinese/chinese_b1\"\n",
    "b1_audio_data = load_audio_data(b1_audio_dir)\n",
    "b1_audio_df = pd.DataFrame(b1_audio_data)\n",
    "\n",
    "b1_df = pd.read_csv(\"data/csv/chinese_b1.csv\")\n",
    "b1_df['file_names'] = b1_df['file_names'].apply(lambda x: x + '.wav')\n",
    "b1_df = pd.merge(b1_df, b1_audio_df, on='file_names', how='inner')\n",
    "\n",
    "b1_df = b1_df.drop(columns=['remarks'])\n",
    "b1_df = b1_df.dropna(subset=['fluency','spoken_text'])\n",
    "dict_data = b1_df.to_dict(orient='list')\n",
    "\n",
    "audio_dataset = Dataset.from_dict(dict_data).cast_column(\"audio_path\", Audio())\n",
    "audio_dataset.train_test_split(test_size=0.2).push_to_hub('chinese_b1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chinese_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39669e19ffc449dcb03162fcab89fc09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a45c93a8194f67a1de79beee7f336a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20180a6a6604f55bea8d16d69bdfee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d464fc286494cf385490a380e45aa2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72502f0059944334ae50cf7963dcf8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888de8f1c42c426998cd619a9fd1e7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/avintech/chinese_b2/commit/1794fa3241060dc1eadc64e4c59927aa8e543156', commit_message='Upload dataset', commit_description='', oid='1794fa3241060dc1eadc64e4c59927aa8e543156', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_dir = \"data/recordings/chinese/chinese_b2\"\n",
    "audio_data = load_audio_data(audio_dir)\n",
    "df = pd.DataFrame(audio_data)\n",
    "\n",
    "b2_df = pd.read_csv(\"data/csv/chinese_b2.csv\")\n",
    "df = pd.merge(df, b2_df, on='file_names', how='inner')\n",
    "\n",
    "dict_data = df.to_dict(orient='list')\n",
    "audio_dataset = Dataset.from_dict(dict_data).cast_column(\"audio_path\", Audio())\n",
    "\n",
    "audio_dataset.train_test_split(test_size=0.2).push_to_hub('chinese_b2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload Malay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malay batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cee3361fc734bc9a916b78b70a543b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5428c5de40f9495fb16ac795dba5ad06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/39 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d819f0c51b284e90abe1f15ca009aac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e6cb92d71c45b08477847d4560bcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550d9b4ecd7f459ba8bbac9fb705cd0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acfe3df31b14fc897035b85e96743e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/avintech/malay_batch1/commit/c3f97b6079f4272a0f3190d6a54635d0543bf153', commit_message='Upload dataset', commit_description='', oid='c3f97b6079f4272a0f3190d6a54635d0543bf153', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_dir = \"data/recordings/malay/malay_batch1\"\n",
    "audio_data = load_audio_data(audio_dir)\n",
    "df = pd.DataFrame(audio_data)\n",
    "\n",
    "b1_df = pd.read_csv(\"data/csv/malay_batch1.csv\")\n",
    "b1_df = b1_df.drop(columns=['remarks'])\n",
    "df = pd.merge(df, b1_df, on='file_names', how='inner')\n",
    "\n",
    "dict_data = df.to_dict(orient='list')\n",
    "audio_dataset = Dataset.from_dict(dict_data).cast_column(\"audio_path\", Audio())\n",
    "\n",
    "audio_dataset.train_test_split(test_size=0.2).push_to_hub('malay_batch1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload Tamil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload ALL tamil together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3f244c09444659b17e9caf96b54903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa39643d15942c09c2a7fe96a4bef1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/642 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b48e53a732241f68e664834e94a5fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cfa2b957864e26ab84addafb178842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c4538bd5f2490dadb3f8b4a688e38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/161 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad7e826d6ed4cf78ad3f18ddfafcb18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e12c952322d4047bb836fa3fe891136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/561 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/avintech/tamil_children_speech/commit/986f9bf89bbfff0bb3f70539d4ebe1027f9ec59b', commit_message='Upload dataset', commit_description='', oid='986f9bf89bbfff0bb3f70539d4ebe1027f9ec59b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_audio_dir = \"data/recordings/tamil/tamil_b1\"\n",
    "b1_audio_data = load_audio_data(b1_audio_dir)\n",
    "b1_audio_df = pd.DataFrame(b1_audio_data)\n",
    "\n",
    "b1_df = pd.read_csv(\"data/csv/tamil_b1.csv\")\n",
    "b1_df = pd.merge(b1_df, b1_audio_df, on='file_names', how='inner')\n",
    "\n",
    "b2_audio_dir = \"data/recordings/tamil/tamil_b2\"\n",
    "b2_audio_data = load_audio_data(b2_audio_dir)\n",
    "b2_audio_df = pd.DataFrame(b2_audio_data)\n",
    "\n",
    "b2_df = pd.read_csv(\"data/csv/tamil_b2.csv\")\n",
    "b2_df = pd.merge(b2_df, b2_audio_df, on='file_names', how='inner')\n",
    "\n",
    "b3_audio_dir = \"data/recordings/tamil/tamil_b3\"\n",
    "b3_audio_data = load_audio_data(b3_audio_dir)\n",
    "b3_audio_df = pd.DataFrame(b3_audio_data)\n",
    "\n",
    "b3_df = pd.read_csv(\"data/csv/tamil_b3.csv\")\n",
    "b3_df = pd.merge(b3_df, b3_audio_df, on='file_names', how='inner')\n",
    "\n",
    "b4_all_audio_dir = \"data/recordings/tamil/tamil_b4_all\"\n",
    "b4_all_audio_data = load_audio_data(b4_all_audio_dir)\n",
    "b4_all_audio_df = pd.DataFrame(b4_all_audio_data)\n",
    "\n",
    "b4_all_df = pd.read_csv(\"data/csv/tamil_b4_all.csv\")\n",
    "b4_all_df = pd.merge(b4_all_df, b4_all_audio_df, on='file_names', how='inner')\n",
    "\n",
    "b4_p1_audio_dir = \"data/recordings/tamil/tamil_b4_p1\"\n",
    "b4_p1_audio_data = load_audio_data(b4_p1_audio_dir)\n",
    "b4_p1_audio_df = pd.DataFrame(b4_p1_audio_data)\n",
    "\n",
    "b4_p1_df = pd.read_csv(\"data/csv/tamil_b4_p1.csv\")\n",
    "b4_p1_df = pd.merge(b4_p1_df, b4_p1_audio_df, on='file_names', how='inner')\n",
    "\n",
    "b4_p2_audio_dir = \"data/recordings/tamil/tamil_b4_p2\"\n",
    "b4_p2_audio_data = load_audio_data(b4_p2_audio_dir)\n",
    "b4_p2_audio_df = pd.DataFrame(b4_p2_audio_data)\n",
    "\n",
    "b4_p2_df = pd.read_csv(\"data/csv/tamil_b4_p2.csv\")\n",
    "b4_p2_df = pd.merge(b4_p2_df, b4_p2_audio_df, on='file_names', how='inner')\n",
    "\n",
    "b5_audio_dir = \"data/recordings/tamil/tamil_b5\"\n",
    "b5_audio_data = load_audio_data(b5_audio_dir)\n",
    "b5_audio_df = pd.DataFrame(b5_audio_data)\n",
    "\n",
    "b5_df = pd.read_csv(\"data/csv/tamil_b5.csv\")\n",
    "b5_df = pd.merge(b5_df, b5_audio_df, on='file_names', how='inner')\n",
    "\n",
    "#merge b1 and b2\n",
    "df = pd.concat([b1_df, b2_df,b3_df, b4_all_df,b4_p1_df, b4_p2_df,b5_df], ignore_index=True)\n",
    "df = df.drop(columns=['remarks'])\n",
    "df = df.dropna(subset=['fluency','spoken_text'])\n",
    "\n",
    "dict_data = df.to_dict(orient='list')\n",
    "audio_dataset = Dataset.from_dict(dict_data).cast_column(\"audio_path\", Audio())\n",
    "\n",
    "audio_dataset.train_test_split(test_size=0.2).push_to_hub('tamil_children_speech')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

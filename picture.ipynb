{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"昨天在公园里，一位年轻的母亲带着她的孩子在草地上野餐，因为天气很好，他们用餐布铺在地上，吃着美味的食物。\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary Richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总词数: 36\n",
      "独特词汇数: 28\n",
      "Type-Token Ratio (TTR): 0.7777777777777778\n",
      "Root Type-Token Ratio (RTTR): 4.666666666666667\n",
      "Hapax Legomena Ratio: 0.6666666666666666\n",
      "Shannon Entropy: 4.627986806877673\n",
      "Vocabulary Richness Score: 0.7962\n",
      "\n",
      "Vocabulary Richness Percentage: 79.62\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import jieba\n",
    "\n",
    "# 分词结果\n",
    "words = jieba.lcut(text)\n",
    "\n",
    "# 总词数\n",
    "total_words = len(words)\n",
    "\n",
    "# 独特词汇数\n",
    "unique_words = set(words)\n",
    "num_unique_words = len(unique_words)\n",
    "\n",
    "# 计算Type-Token Ratio (TTR)\n",
    "ttr = num_unique_words / total_words\n",
    "\n",
    "# 计算Root Type-Token Ratio (RTTR)\n",
    "rttr = num_unique_words / np.sqrt(total_words)\n",
    "\n",
    "# 计算Hapax Legomena Ratio\n",
    "hapax_legomena = [word for word, count in Counter(words).items() if count == 1]\n",
    "hapax_legomena_ratio = len(hapax_legomena) / total_words\n",
    "\n",
    "# 计算Shannon Entropy\n",
    "frequencies = Counter(words).values()\n",
    "word_probs = [freq / total_words for freq in frequencies]\n",
    "shannon_entropy = -sum(p * np.log2(p) for p in word_probs)\n",
    "\n",
    "print(\"总词数:\", total_words)\n",
    "print(\"独特词汇数:\", num_unique_words)\n",
    "print(\"Type-Token Ratio (TTR):\", ttr)\n",
    "print(\"Root Type-Token Ratio (RTTR):\", rttr)\n",
    "print(\"Hapax Legomena Ratio:\", hapax_legomena_ratio)\n",
    "print(\"Shannon Entropy:\", shannon_entropy)\n",
    "\n",
    "# Normalize the metrics\n",
    "normalized_ttr = ttr\n",
    "normalized_rttr = rttr / np.sqrt(total_words)\n",
    "normalized_hapax = hapax_legomena_ratio\n",
    "\n",
    "# Normalize Shannon Entropy\n",
    "max_entropy = np.log2(num_unique_words) if num_unique_words > 0 else 1\n",
    "normalized_entropy = shannon_entropy / max_entropy if max_entropy > 0 else 0\n",
    "\n",
    "# Combine normalized metrics with equal weights\n",
    "vocabulary_richness_score = (\n",
    "    normalized_ttr + \n",
    "    normalized_rttr + \n",
    "    normalized_hapax + \n",
    "    normalized_entropy\n",
    ") / 4\n",
    "\n",
    "# Convert to percentage\n",
    "vocabulary_richness_percentage = vocabulary_richness_score * 100\n",
    "\n",
    "# Print final score\n",
    "print(f\"Vocabulary Richness Score: {vocabulary_richness_score:.4f}\")\n",
    "print()\n",
    "print(f\"Vocabulary Richness Percentage: {vocabulary_richness_percentage:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5W1H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "Who: 年轻的母亲和她的孩子\n",
      "What: 在草地上野餐\n",
      "Where: 公园里\n",
      "When: 昨天\n",
      "Why: 因为天气很好\n",
      "How: 他们用餐布铺在地上，吃着美味的食物。\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "\n",
    "# Initialize the model\n",
    "model = GPT4All(\"mistral-7b-instruct-v0.1.Q4_0.gguf\")\n",
    "\n",
    "# Generate 5W1H response\n",
    "prompt = (\n",
    "    text +\n",
    "    \"based on the text, identify what are the 5W1H in Chinese\"\n",
    ")\n",
    "\n",
    "# Generate response with specific parameters for consistency\n",
    "#temp=0 reduce randomness\n",
    "output = model.generate(prompt, temp=0)\n",
    "\n",
    "# Print the output\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping malformed line: .\n",
      "Skipping malformed line: \n",
      "Evaluation: {'Who': 1, 'What': 1, 'Where': 1, 'When': 1, 'Why': 1, 'How': 1}\n",
      "Total Score: 6\n",
      "\n",
      "5W1H Score: 100.0\n"
     ]
    }
   ],
   "source": [
    "def parse_input(input_str):\n",
    "    # Split the input string into lines\n",
    "    lines = input_str.strip().split('\\n')\n",
    "    \n",
    "    # Create a dictionary from the lines\n",
    "    details = {}\n",
    "    for line in lines:\n",
    "        if ': ' in line:\n",
    "            key, value = line.split(': ', 1)  # Split only on the first occurrence of ': '\n",
    "            details[key] = value\n",
    "        else:\n",
    "            print(f\"Skipping malformed line: {line}\")\n",
    "    \n",
    "    return details\n",
    "\n",
    "def evaluate_details(details):\n",
    "    # Ensure details is a dictionary\n",
    "    if not isinstance(details, dict):\n",
    "        raise TypeError(\"Details should be a dictionary.\")\n",
    "    \n",
    "    # Assign 1 for known, 0 for unknown (\"不明\")\n",
    "    evaluation = {\n",
    "        \"Who\": 1 if details.get(\"Who\") not in [\"不明\", \"不知道\"] else 0,\n",
    "        \"What\": 1 if details.get(\"What\") not in [\"不明\", \"不知道\"] else 0,\n",
    "        \"Where\": 1 if details.get(\"Where\") not in [\"不明\", \"不知道\"] else 0,\n",
    "        \"When\": 1 if details.get(\"When\") not in [\"不明\", \"不知道\"] else 0,\n",
    "        \"Why\": 1 if details.get(\"Why\") not in [\"不明\", \"不知道\"] else 0,\n",
    "        \"How\": 1 if details.get(\"How\") not in [\"不明\", \"不知道\"] else 0\n",
    "    }\n",
    "    \n",
    "    # Calculate the total score\n",
    "    total_score = sum(evaluation.values())\n",
    "    \n",
    "    return evaluation, total_score\n",
    "\n",
    "# Provided input string\n",
    "input_str = output\n",
    "\n",
    "# Parse the input string into a dictionary\n",
    "details = parse_input(input_str)\n",
    "\n",
    "# Evaluate the parsed details\n",
    "evaluation, total_score = evaluate_details(details)\n",
    "\n",
    "whscore = (total_score/6)*100\n",
    "print(f\"Evaluation: {evaluation}\")\n",
    "print(f\"Total Score: {total_score}\")\n",
    "print()\n",
    "print(f\"5W1H Score: {whscore}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "#!pip install jieba transformers sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\itrol\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Similarity: 0.4107\n",
      "\n",
      "Semantic Similarity Score: 41.07\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize jieba for Chinese segmentation\n",
    "def segment(text):\n",
    "    return ' '.join(jieba.cut(text))\n",
    "\n",
    "# Sample Chinese sentences\n",
    "# let sentence1 be transcribed text from student and sentence2 be reference answer\n",
    "\n",
    "reference_text = \"\"\"图片中 是 家里 的 饭厅。现在 应该 是 早餐时间。爸爸、妈妈、姐姐 和 弟弟 一家人 正在 用 早餐。\n",
    "爸爸 的 早餐 是 粥/面汤，妈妈 的 是 面包、因为 他 边 倒 边 看 平板电脑。妈妈 看了 很生气。  \n",
    "姐姐 帮 弟弟 抹/擦掉 倒/溢在 桌子上 的 牛奶/鲜奶/果汁。爸爸 看到了， \n",
    "竖起 大拇指 称赞/夸奖 姐姐\"\"\"\n",
    "\n",
    "sentence2 = \"\"\"\n",
    "图片中 是 家里 的 饭厅。现在 应该 是 早餐时间。爸爸、妈妈、姐姐 和 弟弟 一家人 正在 用 早餐。\n",
    "爸爸 的 早餐 是 粥/面汤，妈妈 的 是 面包、煎蛋 和 咖啡/茶，姐姐 和 弟弟 的 是 麦片 和 牛奶/鲜奶/果汁。 \n",
    "弟弟 倒 牛奶/果汁时，溢/倒  出来 了，因为 他 边 倒 边 看 平板电脑。妈妈 看了 很生气。  \n",
    "姐姐 帮 弟弟 抹/擦掉 倒/溢在 桌子上 的 牛奶/鲜奶/果汁。爸爸 看到了， \n",
    "竖起 大拇指 称赞/夸奖 姐姐。有一次，我弟弟  吃东西时 不小心 打翻 了 食物， \n",
    "我 有 帮他 清理/抹/擦 桌子。  我 认为 弟弟、妹妹 不小心 做错事时， 作为 哥哥、姐姐的，应该 帮 他们。\n",
    "\"\"\"\n",
    "\n",
    "# Segment the sentences\n",
    "segmented_sentence1 = segment(text)\n",
    "segmented_sentence2 = segment(reference_text)\n",
    "\n",
    "# Load a pre-trained Chinese model from Sentence Transformers\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Encode the segmented sentences to get their embeddings\n",
    "embedding1 = model.encode(segmented_sentence1)\n",
    "embedding2 = model.encode(segmented_sentence2)\n",
    "\n",
    "# Calculate cosine similarity between the two embeddings\n",
    "similarity = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "similarity_score = similarity * 100\n",
    "print(f\"Semantic Similarity: {similarity:.4f}\")\n",
    "print()\n",
    "print(f\"Semantic Similarity Score: {similarity_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"昨天在公园里，一位年轻孩子在草地上野餐，因为天气很好，他们餐布铺在地上，吃着美味的食物。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "A: 9\n"
     ]
    }
   ],
   "source": [
    "model = GPT4All(\"mistral-7b-instruct-v0.1.Q4_0.gguf\")\n",
    "grammar_prompt = (\n",
    "    text1 + \"Based on the sentence, evaluate the grammar by giving a score out of 10\"\n",
    ")\n",
    "\n",
    "# Generate response with specific parameters for consistency\n",
    "#temp=0 reduce randomness\n",
    "grammar_output = model.generate(grammar_prompt, temp=0)\n",
    "print(grammar_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 9\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "score_match = re.search(r\"\\d+\", grammar_output)\n",
    "if score_match:\n",
    "    score = int(score_match.group())\n",
    "    print(f\"Score: {score}\")\n",
    "else:\n",
    "    print(\"No score found in the output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fluency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provided text\n",
    "text_file = \"data/reading-passage.txt\"\n",
    "recording_file = \"data/recordings/chinese/chinese_b2/0dc73844-8d4f-2b00-75f6-c6bc3d267377Text_002_Line_1.wav\"\n",
    "model = '0'\n",
    "lang = 'chinese'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n",
      "树枝上有一个小鸟窝\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itrol\\AppData\\Local\\Temp\\ipykernel_21488\\1621940854.py:15: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio_array, sampling_rate = librosa.load(recording_file, sr=None)\n",
      "c:\\Users\\itrol\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/recordings/chinese/chinese_b2/0dc73844-8d4f-2b00-75f6-c6bc3d267377Text_002_Line_1.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\itrol\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\itrol\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[1;32mc:\\Users\\itrol\\anaconda3\\lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\itrol\\anaconda3\\lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'data/recordings/chinese/chinese_b2/0dc73844-8d4f-2b00-75f6-c6bc3d267377Text_002_Line_1.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(provided_text)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#prepare the new audio and extract features\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m audio_array, sampling_rate \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecording_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m audio_data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m: audio_array, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: sampling_rate}\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(audio_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\itrol\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:183\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[0;32m    180\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\itrol\\anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[0;32m     58\u001b[0m )\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\itrol\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:239\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    236\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43maudioread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[0;32m    242\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32mc:\\Users\\itrol\\anaconda3\\lib\\site-packages\\audioread\\__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\itrol\\anaconda3\\lib\\site-packages\\audioread\\rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/recordings/chinese/chinese_b2/0dc73844-8d4f-2b00-75f6-c6bc3d267377Text_002_Line_1.wav'"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "import modules.prepare_data as prepare_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "import librosa\n",
    "\n",
    "with open(text_file, 'r') as file:\n",
    "        provided_text = file.read()\n",
    "\n",
    "print(provided_text)\n",
    "\n",
    "#prepare the new audio and extract features\n",
    "audio_array, sampling_rate = librosa.load(recording_file, sr=None)\n",
    "audio_data = {'array': audio_array, 'sampling_rate': sampling_rate}\n",
    "\n",
    "print(audio_data['array'])\n",
    "print(audio_data['sampling_rate'])\n",
    "\n",
    "data = prepare_data.load_audio(lang,provided_text,audio_data)\n",
    "\n",
    "#use previous scaler to scale the new prediction to fit into the model\n",
    "data = pd.DataFrame([data])\n",
    "data['mfcc'] = data['mfcc'].apply(lambda x: x.flatten())\n",
    "mfcc_length = data['mfcc'].apply(len).max()\n",
    "data['mfcc'] = data['mfcc'].apply(lambda x: np.pad(x, (0, mfcc_length - len(x)), mode='constant'))\n",
    "\n",
    "# Convert mfcc column into multiple columns\n",
    "mfcc_features = np.stack(data['mfcc'].values)\n",
    "df_mfcc = pd.DataFrame(mfcc_features, index=data.index)\n",
    "X = pd.concat([data[['speech_rate', 'pause_rate', 'pronunciation_accuracy']], df_mfcc], axis=1)\n",
    "X.columns = X.columns.astype(str)\n",
    "\n",
    "#Load scalar\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.read_pickle(\"data/pickles/\"+lang+\"_X_train.pkl\")\n",
    "scaler.fit(X_train)\n",
    "\n",
    "#Normalise new data\n",
    "new_data_scaled = scaler.transform(X)\n",
    "\n",
    "# Load the model from the file\n",
    "# 0 for XGBoost, 1 for Random Forest\n",
    "print(model)\n",
    "if model == '0':\n",
    "    loaded_model = keras.models.load_model('models/model_'+lang+'.keras')\n",
    "elif model == '1':\n",
    "    loaded_model = load('models/random_forest_model.joblib')\n",
    "else:\n",
    "    exit\n",
    "\n",
    "y_pred = loaded_model.predict(new_data_scaled)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "fluency_score = int((y_pred_class[0]/4)*100)\n",
    "print(\"Fluency Score: \" + str(fluency_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Richness: 79.62\n",
      "5W1H: 100.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'similarity_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulary Richness: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvocabulary_richness_percentage\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5W1H: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent Relevance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43msimilarity_score\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrammar: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFluency: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfluency_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'similarity_score' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulary Richness: {vocabulary_richness_percentage:.2f}\")\n",
    "print(f\"5W1H: {whscore}\")\n",
    "print(f\"Content Relevance: {similarity_score:.2f}\")\n",
    "print(f\"Grammar: {score}\")\n",
    "print(f\"Fluency: {fluency_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
